{
 "cells": [
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writeup Project: Advanced Lane Finding Project\n",
    "\n",
    "In the previos preject very fundamental methods were used to determine the geometry of the road. However it was not enough to consider the complex road conditions, for example, curved roads, different lane line colors and so on. With this poject the computer vison algorithms are implemented to find out a precise road geometry, which is one of the most and core topic , since the car can only drive autonomously by knowing the envireoment geometry and acting to it.\n",
    "\n",
    "For this purpose I have implemented the computer vision algorithms in this project. The goals of this project are the following:\n",
    "\n",
    "* Compute the camera calibration matrix and distortion coefficients given a set of chessboard images.\n",
    "* Apply a distortion correction to raw images.\n",
    "* Use color transforms, gradients, etc., to create a thresholded binary image.\n",
    "* Apply a perspective transform to rectify binary image (\"birds-eye view\").\n",
    "* Detect lane pixels and fit to find the lane boundary.\n",
    "* Determine the curvature of the lane and vehicle position with respect to center.\n",
    "* Warp the detected lane boundaries back onto the original image.\n",
    "* Output visual display of the lane boundaries and numerical estimation of lane curvature and vehicle position.\n",
    "\n",
    "The used libraries are liste as follows:\n",
    "```python\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "import cv2\n",
    "import glob\n",
    "import os\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "```\n",
    "\n",
    "\n",
    "[//]: # (Image References)\n",
    "\n",
    "[image1]: ./WriteUp/undistort_cameracalibration_WriteUp.PNG \"Undistorted\"\n",
    "[image2]: ./WriteUp/undist_testRoad_WU.PNG  \"Road Undistorted\"\n",
    "[image3]: ./WriteUp/thresholding_WU.PNG  \"Thresholding\"\n",
    "[image4]: ./WriteUp/combinedThresholding_WU.PNG  \"Combined Thresholding\"\n",
    "[image5]: ./WriteUp/perspectiveTransform_WU.PNG  \" Perspective Transform\"\n",
    "[image6]: ./WriteUp/histogram_WU.PNG  \" histogram \"\n",
    "[image7]: ./WriteUp/slidingwindow_WU.PNG  \" Perspective Transform\"\n",
    "[image8]: ./WriteUp/form2.PNG \n",
    "[image9]: ./WriteUp/curvatureVehPos_WU.PNG \n",
    "[image10]: ./WriteUp/result_WU.PNG \n",
    "\n",
    "\n",
    "Now let's continue to go through each steps to see how I implemented my project.\n",
    "\n",
    "### 1. Compute the camera calibration matrix and distortion coefficients\n",
    "\n",
    "The most of the cameras we are using in recent years, have distortions because of the lenses, the camera producers use. The distorion occurs as we transform image from 3D in the real world into 2D image in the image plane. This distortion makes difficult to describe the road geometry,thus, to detect the object in the envireonment. There are two common distortions, which are radial distortion and tangential distortion. \n",
    "\n",
    "In order to get good result, the fist step is to undistort the image, which includes basically two prepareation steps. The first step is to set object points (3D points in the real world plane) and to set the imagepoints (2D points in the image plane). We use bunch of chessboard images to find image points by finding corners using built-in OpenCV function ` findChessboardCorners`, which provides the corners that are basically our 2D points in the image plane. And also, as I said before we need to prepare also the object points that are basically our 3D points (cornes on the real image through the rows and colums). For that none of calculation is required, but they should be prepared. \n",
    "\n",
    "As soon as the first step is done, now it is time for the second step which is to calibrate the camera. By using the image points and object points as input on the build-in OpenCV function `calibrateCamera` the required outputs are generated, which are camera matrix, distortion coefficients, rotation and translation vectors. \n",
    "\n",
    "I have implemented the following function to perform these two steps as follows:\n",
    "\n",
    "```python \n",
    "def calibCamera():\n",
    "    images = glob.glob('camera_cal/calibration*.jpg') # access all calibration images   \n",
    "    # set the chessboard size\n",
    "    nx = 9\n",
    "    ny = 6\n",
    "    # Store the 3D and 2D points\n",
    "    objpoints = [] # 3D points in the real world plane\n",
    "    imgpoints = [] # 2D points in the image plane\n",
    "    # prepare the object points\n",
    "    objp = np.zeros((ny*nx,3), np.float32)\n",
    "    objp[:,:2] = np.mgrid[0:nx,0:ny].T.reshape(-1,2) \n",
    "    for image in images:\n",
    "        img = mpimg.imread(image) # read the image        \n",
    "     # Use cv2.COLOR_RGB2GRAY if you've read in an image using mpimg.imread(). \n",
    "     # Use cv2.COLOR_BGR2GRAY if you've read in an image using cv2.imread().\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY) # convert the image to gray color space\n",
    "        ret, corners = cv2.findChessboardCorners(gray, (nx,ny), None) # find the chessboard corners \n",
    "        if ret:\n",
    "            imgpoints.append(corners) # fill the image corner points\n",
    "            objpoints.append(objp) # fill the object points in real world plane\n",
    "            # draw the corners\n",
    "            img = cv2.drawChessboardCorners(img, (nx,ny), corners, ret)\n",
    "    #calibrate the camera\n",
    "    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, img.shape[1:], None, None)\n",
    "    return mtx, dist\n",
    "```\n",
    "\n",
    "This function turns out two outputs, which are camera matrix `mtx` and distortion coefficients `dist`. They will be used as input in the next section.  \n",
    "\n",
    "### 2. Apply a distortion correction \n",
    "\n",
    "Now it is time to proceed to the next step, which is to undistort the images using the camera matrix `mtx` and the distortion coeefficients `dist`. \n",
    "\n",
    "I have written the following function to undistort the given image.\n",
    "\n",
    "```python\n",
    "def undistImage(img, mtx, dist):\n",
    "    #undistort the given image\n",
    "    undistImg = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "    return undistImg\n",
    "```\n",
    "\n",
    "This function takes the given image, camera matrix and distortion matrix as inputs, and returns the undistorted image. The example input and output images are in the Figure below.\n",
    "\n",
    "![alt text][image1]\n",
    "\n",
    "This funciton has been also applied to the one of the test road image, and the resulting undistorted image as follows:\n",
    "\n",
    "![alt text][image2]\n",
    "\n",
    "\n",
    "### 3. Create a thresholded binary image\n",
    "\n",
    "In the preivous project we have used the built-in function `Canny` to detect the edges using prespecified the minimum and maximim threshold. However for the advanced line finding it is not enough. Therefore I have used different thresholding techniques in order to detect the edges. The techniques which I have used are as follows:\n",
    "\n",
    "    - Gradient Thresholding using Sobel through x axis and y axis\n",
    "    - Magnitude Gradient Thresholding\n",
    "    - Direction of the gradient Thresholding\n",
    "    - using HLS color spaces Thresholding \n",
    "    \n",
    "I have tried all above mentioned methods alone to find out which one is better than other. At the end i have written an algorithm to use the combination of them. The results are in the following Figure.\n",
    "\n",
    "```python\n",
    "def abs_sobel_thresh(img, orient='x', sobel_kernel=3, thresh=(0, 255)):\n",
    "    # Calculate directional gradient\n",
    "    # Apply threshold  \n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_RGB2GRAY)\n",
    "    # 2) Take the gradient in x and y separately\n",
    "    if orient == 'x':\n",
    "        gradx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "        abs_gradx = np.sqrt(np.power(gradx,2))\n",
    "        scaled_grad= np.uint8(255*abs_gradx/np.max(abs_gradx))\n",
    "        grad_binary = np.zeros_like(scaled_grad)\n",
    "        grad_binary[(scaled_grad >= thresh[0]) & (scaled_grad <= thresh[1])] = 1\n",
    "    elif orient == 'y':    \n",
    "        grady = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "        abs_grady = np.sqrt(np.power(grady,2))\n",
    "        scaled_grad= np.uint8(255*abs_grady/np.max(abs_grady))\n",
    "        grad_binary = np.zeros_like(scaled_grad)\n",
    "        grad_binary[(scaled_grad >= thresh[0]) & (scaled_grad <= thresh[1])] = 1   \n",
    "    return grad_binary\n",
    "\n",
    "def mag_thresh(img, sobel_kernel=3, thresh=(0, 255)):\n",
    "    # Calculate gradient magnitude\n",
    "    # Apply threshold\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_RGB2GRAY)\n",
    "    # Take the gradient in x and y separately\n",
    "    gradx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    grady = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "    # Take the absolute value of the x and y gradients\n",
    "    abs_grad = np.sqrt(np.power(gradx,2)+np.power(grady,2))\n",
    "    # Create a binary mask where direction thresholds are met\n",
    "    scaled_sobel = np.uint8(255*abs_grad/np.max(abs_grad))\n",
    "    mag_binary = np.zeros_like(scaled_sobel)\n",
    "    mag_binary[(scaled_sobel >= thresh[0]) & (scaled_sobel <= thresh[1])] = 1  \n",
    "    return mag_binary\n",
    "\n",
    "def dir_thresh(img, sobel_kernel=3, thresh=(0, np.pi/2)):\n",
    "    # Calculate gradient direction\n",
    "    # Apply threshold\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_RGB2GRAY)\n",
    "    # Take the gradient in x and y separately\n",
    "    gradx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    grady = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "    # Take the absolute value of the x and y gradients\n",
    "    abs_gradx = np.sqrt(np.power(gradx,2))\n",
    "    abs_grady = np.sqrt(np.power(grady,2))\n",
    "    # Use np.arctan2(abs_sobely, abs_sobelx) to calculate the direction of the gradient \n",
    "    dir_grad = np.arctan2(abs_grady,abs_gradx)\n",
    "    # Create a binary mask where direction thresholds are met\n",
    "    dir_binary = np.zeros_like(dir_grad)\n",
    "    dir_binary[(dir_grad >= thresh[0]) & (dir_grad <= thresh[1])] = 1\n",
    "    return dir_binary\n",
    "\n",
    "def hls_thresh(img):\n",
    "    hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "    h = hls[:,:,0]\n",
    "    l = hls[:,:,1]\n",
    "    s = hls[:,:,2]\n",
    "    thresh_h = (10,60)\n",
    "    thresh_l = (200,255)\n",
    "    thresh_s = (90,255)\n",
    "    h_binary = np.zeros_like(h)\n",
    "    h_binary[(h >= thresh_h[0]) & (h <= thresh_h[1])] = 1\n",
    "    l_binary = np.zeros_like(l)\n",
    "    l_binary[(l >= thresh_l[0]) & (l <= thresh_h[1])] = 1\n",
    "    s_binary = np.zeros_like(s)\n",
    "    s_binary[(s >= thresh_s[0]) & (s <= thresh_s[1])] = 1\n",
    "    \n",
    "    combined_hs = np.zeros_like(h)\n",
    "    #combined_hs[((h_binary == 1) | (s_binary == 1)) | (l_binary==1) ] = 1\n",
    "    combined_hs[((s_binary == 1)) | (l_binary==1) ] = 1\n",
    "    #combined_hs[((h_binary == 1) | (s_binary == 1))] = 1\n",
    "    #combined_hs[((s_binary == 1))] = 1\n",
    "    return combined_hs\n",
    "```\n",
    "\n",
    "![alt text][image3]\n",
    "\n",
    "As I said before, because I am not satisfied of the above results, I have implemented the combination of all methods. The function I have written and the result are as follows:  \n",
    "\n",
    "```python\n",
    "def combinedThresh(img):\n",
    "    kernel_size = 9\n",
    "    grad_binaryX = abs_sobel_thresh(img, orient='x', sobel_kernel=kernel_size,  thresh=(20, 100))\n",
    "    grad_binaryY = abs_sobel_thresh(img, orient='y', sobel_kernel=kernel_size, thresh=(20, 100))\n",
    "    mag_binary = mag_thresh(img, sobel_kernel=kernel_size, thresh=(50, 100))\n",
    "    dir_binary = dir_thresh(img, sobel_kernel=kernel_size, thresh=(0.7, 1.3))\n",
    "    hls_binary = hls_thresh(img)\n",
    "    \n",
    "    combined = np.zeros_like(dir_binary)\n",
    "    combined[(grad_binaryX == 1) | ((mag_binary == 1) & (dir_binary == 1)) | (hls_binary == 1) ] = 1\n",
    "    return combined\n",
    "```\n",
    "![alt text][image4]\n",
    "\n",
    "As it is clearly seen, the combined thresholding algorithm provides us much better edge detection result. Now it is time to move the next section.\n",
    "\n",
    "By the way it has taken a lot time to find the best version :). \n",
    "\n",
    "### 4. Apply a perspective transform\n",
    "\n",
    "In order to calculate the lane curvature the prespective transform is needed to apply, which basically trasnforms the image in a bird-eye view (top-down view). The basic idea is to grab four points forming rectangular area from the source image, and also four points forming rectangular area that will be destionation points. The selecting procedure was intuitive in my case, I have tried may points combination to find the best source and destination points.\n",
    "\n",
    "For the perspective transform I have implemented another function, taking an image as input, then delivers the warped image, trasnfomation matrix, and inverse trasnformation matrix for getting image back later. The function and the result are as follows. I have used the starting point from the gevien write_up, and the I have changed it with respect to resulting image.\n",
    "\n",
    "\n",
    "```python\n",
    "def perspectiveTransform(img):\n",
    "\n",
    "    src = np.float32([\n",
    "        [700, 450], # top right\n",
    "        [1100, img.shape[0] ], # bottom right\n",
    "        [180, img.shape[0]], # bottom left\n",
    "        [600, 450]]) # top left   \n",
    "            # c) define 4 destination points dst = np.float32([[,],[,],[,],[,]])\n",
    "    dst = np.float32([\n",
    "        [980,0],             # top right\n",
    "        [980,img.shape[0]],  # bottom right\n",
    "        [300,img.shape[0]],  # bottom left\n",
    "        [300,0]])            # top left  \n",
    "    '''\n",
    "    src = np.float32([\n",
    "        [680, 460],            # top right\n",
    "        [1050, img.shape[0] ], # bottom right\n",
    "        [200, img.shape[0]],   # bottom left\n",
    "        [550, 460]])           # top left   \n",
    "    #  define 4 destination points dst = np.float32([[,],[,],[,],[,]])\n",
    "    dst = np.float32([\n",
    "        [900,0],             # top right\n",
    "        [980,img.shape[0]],  # bottom right\n",
    "        [440,img.shape[0]],  # bottom left\n",
    "        [410,0]])            # top left  \n",
    "    '''\n",
    "    # get M, the transform matrix\n",
    "    M = cv2.getPerspectiveTransform(src, dst) \n",
    "    # get inverse M, the transform matrix, to transform the perspective image back to original image\n",
    "    M_inv = cv2.getPerspectiveTransform(dst, src)\n",
    "    # warp an image to a top-down view\n",
    "    warped = cv2.warpPerspective(img, M, (img.shape[1], img.shape[0]), flags=cv2.INTER_LINEAR)\n",
    "    return warped, M, M_inv\n",
    "```\n",
    "\n",
    "![alt text][image5]\n",
    "\n",
    "It is important to mention at this point that I used the combined thresholded image as input from the previous step. The result looks very good im my opinion and we can see the curvature from top. Let's continue to dive more with next steps.\n",
    "\n",
    "### 5. Detect lane pixels and fit to find the lane boundary \n",
    "\n",
    "It is now time to detect the lane lines pixels and fit them into the polynom which generates the curve line that will help to calculate the curvature, after applying calibration, thresholdingm and a perspective transform to a road image. Here the first step is to decide which line is the right and which one is the left using histogram which shows where the binary activations occur across the image. With this histogram we are adding up the pixel values along each column in the image. The result of histogram is as follows:\n",
    "```python \n",
    "histogram = np.sum(binary_warped[binary_warped.shape[0]//2:,:], axis=0)\n",
    "plt.plot(histogram)\n",
    "```\n",
    "![alt text][image6]\n",
    "\n",
    "If the figure in previous section and the figure in this section are compared, one can see that the histogram value is getting high where the lane lines occured. \n",
    "\n",
    "The next point is to use sliding windows moving upward in the image to determine where the lines go. For this purpose I have written three functions to implement my algorithm as folows:\n",
    "\n",
    "```python\n",
    "def find_lane_pixels(binary_warped):\n",
    "     # Create an output image to draw on and visualize the result\n",
    "    out_img = np.dstack((binary_warped, binary_warped, binary_warped))*255\n",
    "    # Take a histogram of the bottom half of the image\n",
    "    histogram = np.sum(binary_warped[binary_warped.shape[0]//2:,:], axis=0)\n",
    "    # Find the peak of the left and right halves of the histogram\n",
    "    # These will be the starting point for the left and right lines\n",
    "    midpoint = np.int(histogram.shape[0]//2)\n",
    "    leftx_base = np.argmax(histogram[:midpoint])\n",
    "    rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
    "\n",
    "    # HYPERPARAMETERS\n",
    "    # Choose the number of sliding windows\n",
    "    nwindows = 9\n",
    "    # Set the width of the windows +/- margin\n",
    "    margin = 100\n",
    "    # Set minimum number of pixels found to recenter window\n",
    "    minpix = 50\n",
    "\n",
    "    # Set height of windows - based on nwindows above and image shape\n",
    "    window_height = np.int(binary_warped.shape[0]//nwindows)\n",
    "   \n",
    "    # Identify the x and y positions of all nonzero pixels in the image\n",
    "    nonzero = binary_warped.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    # Current positions to be updated later for each window in nwindows\n",
    "    leftx_current = leftx_base\n",
    "    rightx_current = rightx_base\n",
    "   \n",
    "    # Create empty lists to receive left and right lane pixel indices\n",
    "    left_lane_inds = []\n",
    "    right_lane_inds = []\n",
    "\n",
    "    # Step through the windows one by one\n",
    "    for window in range(nwindows):\n",
    "        # Identify window boundaries in x and y (and right and left)\n",
    "        win_y_low = binary_warped.shape[0] - (window+1)*window_height\n",
    "        win_y_high = binary_warped.shape[0] - window*window_height\n",
    "        win_xleft_low = leftx_current - margin\n",
    "        win_xleft_high = leftx_current + margin\n",
    "        win_xright_low = rightx_current - margin\n",
    "        win_xright_high = rightx_current + margin\n",
    "        \n",
    "        # Draw the windows on the visualization image\n",
    "        cv2.rectangle(out_img,(win_xleft_low,win_y_low),\n",
    "        (win_xleft_high,win_y_high),(0,255,0), 2) \n",
    "        cv2.rectangle(out_img,(win_xright_low,win_y_low),\n",
    "        (win_xright_high,win_y_high),(0,255,0), 2) \n",
    "        \n",
    "        # Identify the nonzero pixels in x and y within the window #\n",
    "        good_left_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & \n",
    "        (nonzerox >= win_xleft_low) &  (nonzerox < win_xleft_high)).nonzero()[0]\n",
    "        good_right_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & \n",
    "        (nonzerox >= win_xright_low) &  (nonzerox < win_xright_high)).nonzero()[0]\n",
    "        \n",
    "        # Append these indices to the lists\n",
    "        left_lane_inds.append(good_left_inds)\n",
    "        right_lane_inds.append(good_right_inds)\n",
    "        \n",
    "        # If you found > minpix pixels, recenter next window on their mean position\n",
    "        if len(good_left_inds) > minpix:\n",
    "            leftx_current = np.int(np.mean(nonzerox[good_left_inds]))\n",
    "          \n",
    "        if len(good_right_inds) > minpix:        \n",
    "            rightx_current = np.int(np.mean(nonzerox[good_right_inds]))\n",
    "           \n",
    "    # Concatenate the arrays of indices (previously was a list of lists of pixels)\n",
    "    try:\n",
    "        left_lane_inds = np.concatenate(left_lane_inds)\n",
    "        right_lane_inds = np.concatenate(right_lane_inds)\n",
    "    except ValueError:\n",
    "        # Avoids an error if the above is not implemented fully\n",
    "        pass\n",
    "\n",
    "    # Extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds] \n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds]\n",
    "\n",
    "    return leftx, lefty, rightx, righty, out_img\n",
    "\n",
    "def fit_polynomial(leftx, lefty, rightx, righty):   \n",
    "    # Fit a second order polynomial to each using `np.polyfit`\n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "    return left_fit, right_fit\n",
    "\n",
    "def drawImage(binary_warped, left_fit, right_fit, out_img):  \n",
    "    # Generate x and y values for plotting\n",
    "    ploty = np.linspace(0, binary_warped.shape[0]-1, binary_warped.shape[0] )\n",
    "    try:\n",
    "        left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "        right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "    except TypeError:\n",
    "        # Avoids an error if `left` and `right_fit` are still none or incorrect\n",
    "        print('The function failed to fit a line!')\n",
    "        left_fitx = 1*ploty**2 + 1*ploty\n",
    "        right_fitx = 1*ploty**2 + 1*ploty\n",
    "\n",
    "    ## Visualization ##\n",
    "    # Colors in the left and right lane regions\n",
    "    out_img[lefty, leftx] = [255, 0, 0]\n",
    "    out_img[righty, rightx] = [0, 0, 255]\n",
    "    plt.imshow(out_img.astype('uint8'))\n",
    "    # Plots the left and right polynomials on the lane lines\n",
    "    plt.plot(left_fitx, ploty, color='yellow')\n",
    "    plt.plot(right_fitx, ploty, color='yellow')\n",
    "    return out_img\n",
    "```\n",
    "The resulting image is as follows:\n",
    "\n",
    "![alt text][image7]\n",
    "\n",
    "With this result, we can now calculate the curvature in the next section.\n",
    "\n",
    "### 6. Determine the curvature of the lane and vehicle position with respect to center\n",
    "\n",
    "In this section the radius of the curvature is calculated. I have implemented the following formulas to calculate the curvature:\n",
    "\n",
    "![image.png](attachment:image.png)\n",
    "![alt text][image8]\n",
    "\n",
    "As soon as we find the left and right lines we can calculate the center of the lane, then we can use the middle of the image on the axis and the center of the lines to be able to calculate the vehicle position with respect to the center of the line. This idea is also implemented into the function given below.\n",
    "\n",
    "So far only the lane pixels' values are used for all calculation, but in the real world it needs one mor transformation, which is basically the conversion of the `pixels` to the SI `meter`. For that puprpose as we have learned in the class, I had efined the conversion coeefficients `ym_per_pix = 30/720`, 30 meters per 720 pixels, in vertical direction, and `xm_per_pix = 3.7/700` , 3.7 meters per 700 pixels, in horizantal direction. Theseb conversion is used for both calculation of radius of curve and vehicle position.\n",
    "\n",
    "For the vehicle position calculation I took the center of the lane as reference with assuming that the vehicle's position is on the middle of the horizantal axis, and then I have calculated the center of the found left and right line. Then I checked how big is the offset between these two.\n",
    "\n",
    "I have implemented the following function to calculate the curvature and the vehicle position with respect to the center.\n",
    "\n",
    "```python\n",
    "def cal_Curvature_VehPos(binary_warped):\n",
    "    '''\n",
    "    Calculates the curvature of polynomial functions and vehicle position with respect to center in meters.\n",
    "    '''\n",
    "    # Define conversions in x and y from pixels space to meters\n",
    "    ym_per_pix = 30/720 # meters per pixel in y dimension\n",
    "    xm_per_pix = 3.7/700 # meters per pixel in x dimension\n",
    "    \n",
    "    # Find lane pixels and fit in polynom to find polynom's coeefficents\n",
    "    leftx, lefty, rightx, righty, out_img = find_lane_pixels(binary_warped)  \n",
    "    left_fit, right_fit = fit_polynomial(leftx, lefty, rightx, righty)\n",
    "\n",
    "    # Fit new polynomials to x,y in world space    \n",
    "    ploty = np.linspace(0, binary_warped.shape[0]-1, binary_warped.shape[0] )\n",
    "    try:\n",
    "        left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "        right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "    except TypeError:\n",
    "        # Avoids an error if `left` and `right_fit` are still none or incorrect\n",
    "        print('The function failed to fit a line!')\n",
    "        left_fitx = 1*ploty**2 + 1*ploty\n",
    "        right_fitx = 1*ploty**2 + 1*ploty    \n",
    "    \n",
    "    ##### Utilize `ym_per_pix` & `xm_per_pix` here #####\n",
    "    left_fit_cr = np.polyfit(ploty*ym_per_pix, left_fitx*xm_per_pix, 2)\n",
    "    right_fit_cr = np.polyfit(ploty*ym_per_pix, right_fitx*xm_per_pix, 2)\n",
    "    \n",
    "    # Define y-value where we want radius of curvature\n",
    "    # We'll choose the maximum y-value, corresponding to the bottom of the image\n",
    "    y_eval = binary_warped.shape[0]\n",
    "    \n",
    "    # Implement the calculation of R_curve on the left and on the right (radius of curvature)\n",
    "    left_curverad = ((1 + (2*left_fit_cr[0]*y_eval*ym_per_pix + left_fit_cr[1])**2)**1.5) / np.absolute(2*left_fit_cr[0])\n",
    "    right_curverad = ((1 + (2*right_fit_cr[0]*y_eval*ym_per_pix + right_fit_cr[1])**2)**1.5) / np.absolute(2*right_fit_cr[0])\n",
    "    curvature = (left_curverad + right_curverad)//2\n",
    "    \n",
    "     # Calculate left and right line positions at the bottom of the image\n",
    "    left_line_x_pos = (left_fit[0]*(y_eval**2))+(left_fit[1]*y_eval)+left_fit[2]\n",
    "    right_line_x_pos = (right_fit[0]*(y_eval**2))+(right_fit[1]*y_eval)+right_fit[2]\n",
    "\n",
    "    mid_lanes_x_pos = (left_line_x_pos + right_line_x_pos)//2 # calculate the average curvature\n",
    "        \n",
    "    x_mid = binary_warped.shape[1]//2\n",
    "        \n",
    "    vehPos_offset = (mid_lanes_x_pos- x_mid) * xm_per_pix # find the vehicle position on the real world\n",
    "    \n",
    "    return ploty, left_fitx, right_fitx, left_curverad, right_curverad, curvature, veh_pos\n",
    "```\n",
    "This function takes the warped image as input and returns the curvature and vehicle position. The result for the above given warped image is as below:\n",
    "\n",
    "![alt text][image9]\n",
    "\n",
    "\n",
    "### 7. Warp the detected lane boundaries back onto the original image\n",
    "\n",
    "This section enables us to trasnform the image back to the original view and write all information on it , which are the radius of the curvature and the vehicle position with respect to the center. I have written the following function to implement my algorithm as follows.\n",
    "\n",
    "```python\n",
    "def pipeline(img):\n",
    "    mtx, dist = calibCamera()\n",
    "    undistImg = undistImage(img, mtx, dist)\n",
    "    \n",
    "    combined = combinedThresh(img)\n",
    "    \n",
    "    binary_warped, M, M_inv = perspectiveTransform(combined)\n",
    "    ploty, left_fitx, right_fitx, left_curverad, right_curverad, curvature, veh_pos = cal_Curvature_VehPos(binary_warped)\n",
    "    \n",
    "    # Create an image to draw the lines on\n",
    "    warp_zero = np.zeros_like(binary_warped).astype(np.uint8)\n",
    "    color_warp = np.dstack((warp_zero, warp_zero, warp_zero))\n",
    "\n",
    "    # Recast the x and y points into usable format for cv2.fillPoly()\n",
    "    pts_left = np.array([np.transpose(np.vstack([left_fitx, ploty]))])\n",
    "    pts_right = np.array([np.flipud(np.transpose(np.vstack([right_fitx, ploty])))])\n",
    "    pts = np.hstack((pts_left, pts_right))\n",
    "\n",
    "    # Draw the lane onto the warped blank image\n",
    "    cv2.fillPoly(color_warp, np.int_([pts]), (0,255, 0))\n",
    "\n",
    "    # Warp the blank back to original image space using inverse perspective matrix (Minv)\n",
    "    newwarp = cv2.warpPerspective(color_warp, M_inv, (img.shape[1], img.shape[0])) \n",
    "    # Combine the result with the original image\n",
    "    result = cv2.addWeighted(undistImg, 1, newwarp, 0.3, 0)\n",
    "    cv2.putText(result,'Radius of Curve in m: '+str(curvature)[:6],(350,70), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (255,255,255),2,cv2.LINE_AA)\n",
    "    cv2.putText(result,'VehPos Offset to Center in m: '+str(veh_pos)[:6],(350,150), cv2.FONT_HERSHEY_SIMPLEX, 1.5,(255,255,255),2,cv2.LINE_AA)\n",
    "    return result\n",
    "``` \n",
    "The resulting image is given in Figure below:\n",
    "\n",
    "![alt text][image10]\n",
    "\n",
    "It looks nice, isn't it? :)\n",
    "\n",
    "### 8. Video Clip Pipeline\n",
    "\n",
    "The last step is to put all above into a pipeline which works not only on image, but also on video. As we know, the video is basically a set of image frame. However we need to track some information from the previous frame like the last lane line pixels. As given in Tips and Tricks for the project, i have decided to implement the class with some important attributes. \n",
    "\n",
    "I need to calculate some section only once, for example, camera calibration matrix and distortion matrix, since the same calibration chessboard images are used all the time. And also I need to calculate the initial lane line pixels at the begining to store them later as the last pixel point for the next calculations. \n",
    "\n",
    "I have implemented the following Class with attributes and one static method to integrate my all functions to process the given video.\n",
    "\n",
    "```python\n",
    "class Line():\n",
    "    def __init__(self):\n",
    "        # if it is first Run\n",
    "        self.firstRun = True # to calculate the initial line pixels only once   \n",
    "        self.cameraCal = True # to calibrate camera only once \n",
    "        self.right_fit=[np.array([False])] # store preivous right line pixels\n",
    "        self.left_fit=[np.array([False])]  # store preivous left line pixels\n",
    "        self.mtx = [np.array([False])]  # store the camera calibration matrix after the first run to use in next runs\n",
    "        self.dist = [np.array([False])] # store the distortion coeeficient matrix after the first run to use in next runs\n",
    "    @staticmethod\n",
    "    def vidPipeline(img):\n",
    "        if Line.cameraCal == True:\n",
    "            print('First run/frame: Camera Calibration Done ')\n",
    "            mtx, dist = calibCamera() #done only once\n",
    "            Line.mtx = mtx \n",
    "            Line.dist = dist\n",
    "            Line.cameraCal = False \n",
    "        else:\n",
    "            mtx = Line.mtx\n",
    "            dist = Line.dist\n",
    "    \n",
    "        undistImg = undistImage(img, mtx, dist) # undistort the image\n",
    "\n",
    "        combined = combinedThresh(img) # calculate the combined thresholding : hls, sobel-,magnitude,direcetional\n",
    "\n",
    "        binary_warped, M, M_inv = perspectiveTransform(combined) # genrater wapred image, and calculate transfromation matrix\n",
    "        \n",
    "        if Line.firstRun == True: \n",
    "            print('First run/frame: Starting Lane Pixels Calculated ')\n",
    "            leftx, lefty, rightx, righty, out_img = find_lane_pixels(binary_warped)\n",
    "            left_fit, right_fit = fit_polynomial(leftx, lefty, rightx, righty)\n",
    "            Line.right_fit = right_fit\n",
    "            Line.left_fit = left_fit\n",
    "            Line.firstRun = False\n",
    "        else:\n",
    "            \n",
    "            left_fit=Line.left_fit # take the previos lane pixel to continue\n",
    "            right_fit=Line.right_fit\n",
    "\n",
    "            margin = 100\n",
    "            nonzero = binary_warped.nonzero()\n",
    "            nonzeroy = np.array(nonzero[0])\n",
    "            nonzerox = np.array(nonzero[1])\n",
    "\n",
    "            left_lane_inds = ((nonzerox > (left_fit[0]*(nonzeroy**2) + left_fit[1]*nonzeroy + \n",
    "                            left_fit[2] - margin)) & (nonzerox < (left_fit[0]*(nonzeroy**2) + \n",
    "                            left_fit[1]*nonzeroy + left_fit[2] + margin))).nonzero()[0]\n",
    "            right_lane_inds = ((nonzerox > (right_fit[0]*(nonzeroy**2) + right_fit[1]*nonzeroy + \n",
    "                            right_fit[2] - margin)) & (nonzerox < (right_fit[0]*(nonzeroy**2) + \n",
    "                            right_fit[1]*nonzeroy + right_fit[2] + margin))).nonzero()[0]\n",
    "\n",
    "            # Extract left and right line pixel positions\n",
    "            leftx = nonzerox[left_lane_inds]\n",
    "            lefty = nonzeroy[left_lane_inds] \n",
    "            rightx = nonzerox[right_lane_inds]\n",
    "            righty = nonzeroy[right_lane_inds]      \n",
    "\n",
    "            # Fit a second order polynomial to pixel positions in each lane line\n",
    "            left_fit, right_fit = fit_polynomial(leftx, lefty, rightx, righty)\n",
    "                        \n",
    "            Line.right_fit = right_fit # store the new polynaomial pixel position for the next frame\n",
    "            Line.left_fit = left_fit\n",
    "\n",
    "        ploty = np.linspace(0, binary_warped.shape[0]-1, binary_warped.shape[0] )\n",
    "        try:\n",
    "            left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "            right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "        except TypeError:\n",
    "            # Avoids an error if `left` and `right_fit` are still none or incorrect\n",
    "            print('The function failed to fit a line!')\n",
    "            left_fitx = 1*ploty**2 + 1*ploty\n",
    "            right_fitx = 1*ploty**2 + 1*ploty    \n",
    "\n",
    "        ym_per_pix = 30/720 # meters per pixel in y dimension\n",
    "        xm_per_pix = 3.7/700 # meters per pixel in x dimension\n",
    "        # Measure the curvature in meter\n",
    "        left_fit_cr = np.polyfit(ploty*ym_per_pix, left_fitx*xm_per_pix, 2)\n",
    "        right_fit_cr = np.polyfit(ploty*ym_per_pix, right_fitx*xm_per_pix, 2)\n",
    "\n",
    "        # Define y-value where we want radius of curvature\n",
    "        # We'll choose the maximum y-value, corresponding to the bottom of the image\n",
    "        y_eval = binary_warped.shape[0]\n",
    "\n",
    "        # Implement the calculation of R_curve on the left and on the right (radius of curvature)\n",
    "        left_curverad = ((1 + (2*left_fit_cr[0]*y_eval*ym_per_pix + left_fit_cr[1])**2)**1.5) / np.absolute(2*left_fit_cr[0])\n",
    "        right_curverad = ((1 + (2*right_fit_cr[0]*y_eval*ym_per_pix + right_fit_cr[1])**2)**1.5) / np.absolute(2*right_fit_cr[0])\n",
    "        curvature = (left_curverad + right_curverad)//2\n",
    "\n",
    "        # Calculate left and right line positions at the bottom of the image\n",
    "        left_line_x_pos = (left_fit[0]*(y_eval**2))+(left_fit[1]*y_eval)+left_fit[2]\n",
    "        right_line_x_pos = (right_fit[0]*(y_eval**2))+(right_fit[1]*y_eval)+right_fit[2]\n",
    "\n",
    "        mid_lanes_x_pos = (left_line_x_pos + right_line_x_pos)//2 # calculate the average curvature\n",
    "        \n",
    "        x_mid = binary_warped.shape[1]//2\n",
    "        \n",
    "        vehPos_offset = (mid_lanes_x_pos- x_mid) * xm_per_pix # find the vehicle position on the real world\n",
    "\n",
    "        # Create an image to draw the lines on\n",
    "        warp_zero = np.zeros_like(binary_warped).astype(np.uint8)\n",
    "        color_warp = np.dstack((warp_zero, warp_zero, warp_zero))\n",
    "\n",
    "        # Recast the x and y points into usable format for cv2.fillPoly()\n",
    "        pts_left = np.array([np.transpose(np.vstack([left_fitx, ploty]))])\n",
    "        pts_right = np.array([np.flipud(np.transpose(np.vstack([right_fitx, ploty])))])\n",
    "        pts = np.hstack((pts_left, pts_right))\n",
    "\n",
    "        # Draw the lane onto the warped blank image\n",
    "        cv2.fillPoly(color_warp, np.int_([pts]), (0,255, 0))\n",
    "\n",
    "        # Warp the blank back to original image space using inverse perspective matrix (Minv)\n",
    "        newwarp = cv2.warpPerspective(color_warp, M_inv, (img.shape[1], img.shape[0])) \n",
    "        # Combine the result with the original image\n",
    "        result = cv2.addWeighted(undistImg, 1, newwarp, 0.3, 0)\n",
    "        cv2.putText(result,'Radius of Curve in m: '+str(curvature)[:6],(350,70), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (255,255,255),2,cv2.LINE_AA)\n",
    "        cv2.putText(result,'VehPos Offset to center in m: '+str(vehPos_offset)[:6],(350,150), cv2.FONT_HERSHEY_SIMPLEX, 1.5,(255,255,255),2,cv2.LINE_AA)\n",
    "        return result\n",
    "```\n",
    "\n",
    "### 9. Result\n",
    "\n",
    "Here's a [link to my video result](./output_videos/output_project_video.mp4). I should say that the result looks nice by detecting the lanes correctly during the entire video.\n",
    "\n",
    "\n",
    "### 10. Discussion\n",
    "\n",
    "For the other given two challenging videos my algorithm was not good enough, especially, for hard_challenge_video. I am going to find out another approaches to make my algorithm more robust against the different road conditions, for example, for very bright road condition better edge detection algorithm, for very curvy roads better lane pixels' fiting polynoms and so on. I am not expert but as soon as I learn neural networks, I think it would also help more to find the edges much more efefective and precise. I am also open for any suggestions to make my code alse better, since I am doing this nonedegree for my hobby and interest, not to find a job :)\n",
    "\n",
    "### References\n",
    "\n",
    "- Udacity self driving cars nonedegree \n",
    "- https://www.intmath.com/applications-differentiation/8-radius-curvature.php\n",
    "- https://docs.opencv.org/2.4/index.html\n",
    "\n",
    "#### Important folders\n",
    "I have put the results of the images and the video into the following folders:\n",
    "\n",
    "[link to my image results](./output_images)\n",
    "\n",
    "[link to my video results](./output_videos)\n",
    "\n",
    "[link to my images for WriteUp](./WriteUp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
